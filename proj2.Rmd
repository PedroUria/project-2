---
title: "Project-2-Markdown"
author: "Sean Pili"
date: "December 1, 2018"
output: html_document
---

```{r install_functions, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
##Helper Functions here for cleanly handling imports
#install_all - function for installing all packages in a list that aren't available
#  inspired by https://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them
#  ex: install_all(c('readr', 'dplyr'))
install_all <- function(list.of.packages) {
  need_install <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
  if(length(need_install)) install.packages(need_install)
}

# package_apply_all - function for calling install_all on list of packages, then applying a function to them
#  inspired by https://stackoverflow.com/questions/8175912/load-multiple-packages-at-once
#  ex: package_apply_all(c('readr', 'dplyr'), require)
package_apply_all <- function(list.of.packages, func) {
  install_all(list.of.packages)
  invisible(lapply(list.of.packages, func, character.only = TRUE))
}
```


```{r imports, include=FALSE}
package_apply_all(
  c(
    'readr', # for loading data from various formats
    'dplyr', # because we all need a little magic
    'ggplot2', # pretty graphs
    'tidyr' # needed for the gather function
  ), require)
```

#Initial Data Gathering and Cleaning

```{r helpers, include=FALSE}
# Pull in Consumer Price Index Data from 
# Burea of Labor Statistics to account for inflation
cpi <- read_csv('CPI_20181201.csv', col_types = cols())
# data ranged from 2000 (1) to 2017 (18)
# so... year mod 2000 + 1 is the indexing scheme.
# NOTE: if cpi csv file is changed the indexing scheme will need updating
cpif <- function(year) {
  idx <- year %% 2000 + 1
  cpi$Annual[idx]
}

```

# Stating the Question

Can we predict how likely a movie is to win an Oscar given information about that movie being nominated to, or winning other awards prior to the Oscars?

TODO: Expand discussion of background some/etc...

# Exploratory Data Analysis



# Model Building

Discussion of choice of model.. both logistic, and penalized for comparison to ensure best possible model... etc...

## Logistic Regression

### Model Validation/Testing

## Penalized Logistic Regression

### Model Validation/Testing

# Interpret (In detail what do the models tell us)

What does the model tell us?

# Communicate (Conclusion?)

Were we able to answer the question?

```{r initialize}
# oscars data
pat.oscar_won <- "Oscar_.*_won$"
pat.oscar_nom <- "Oscar_.*_nominated$"
oscars <- read_csv("oscars.csv", col_types = cols()) %>% mutate(
  # Adjust gross field by Consumer Price Index.
  # cpif provides annual average CPI for specified year
  # data provided by the Burea of Labor Statistics website
  # (implementation included in full Rmd document)
  sc.gross = gross * cpif(2000)/cpif(year) # "In 2000 dollars"
) %>% 
  # mutate oscars won and oscars nominated cols/variables to factor types
  mutate_at(vars(matches(pat.oscar_won)), funs(factor)) %>%
  mutate_at(vars(matches(pat.oscar_nom)), funs(factor))
```

```{r currency_validation}
# Validation of currency adjustment
currency_info <- oscars %>% select(
  gross, sc.gross, year
) %>% mutate(
  diff = gross - sc.gross
) %>% group_by(year) %>% summarize(
  n=n(),
  diff_mn = mean(diff, na.rm = TRUE),
  gross_mn = mean(gross, na.rm = TRUE),
  sc.gross_mn = mean(sc.gross, na.rm = TRUE)
)

currency_info %>% 
  gather(key, value, gross_mn, sc.gross_mn) %>%
  ggplot(aes(x=year, y=value, colour=key)) + 
  geom_line()
```

The CPI based adjustment seems to have behaved as expected.

##

## Pedro's issues

### Target: Won At Least One Oscar

```{r oscars_won_some}
# sum number of wins identified per row for cols
tmp.won <- rowSums(
  oscars %>%
    mutate_at(
      vars(matches(pat.oscar_won)),
      funs(ifelse(. == "No", 0, 1))
    ) %>% select(matches(pat.oscar_won))
  )

# set win count variable in oscars df
oscars <- oscars %>% 
  mutate(Oscars_win_count = tmp.won)

# Validation
oscars_won_best_picture <- filter(oscars, Oscar_Best_Picture_won == 'Yes')
# This movie won 3 oscars, let's see if it checks out
oscars_won_best_picture$Oscars_win_count[1] == 3
# This movie won 2 oscars, let's see if it checks out
oscars_won_best_picture$Oscars_win_count[2] == 2
# Yeap

# Encodes as factor
oscars <- oscars %>% mutate(
  Oscars_won_some = factor(ifelse(Oscars_win_count > 0, "Yes", "No"))
)
```

### Awards_wins

`awards_wins`... does it count the Oscars too?
```{r}
# Gets the movies that won Oscars for best picture 
oscars_won_best_picture <- subset(oscars, Oscar_Best_Picture_won == "Yes")
dim(oscars_won_best_picture)
#View(head(oscars_won_best_picture[c(1:40)]))
# Gets the first movie of such list
lord_of_the_rings_king <- head(oscars_won_best_picture, 1)
#View(lord_of_the_rings_king)
# Gets the number of awards it won, not counting the Oscars 
num_awards_won <- 0
# For every column name in the Series
for (i in names(lord_of_the_rings_king)){
  # If "won"" is in such name
  if(grepl("won", i) == TRUE){
    # And if "Oscar" and "categories" is not
     if(grepl("Oscar", i) == FALSE){
       if(grepl("categories", i) == FALSE){
         # Add to num_awards_won the value of such column
         num_awards_won = num_awards_won + lord_of_the_rings_king[c(i)][[1]]
       }
      }
  }
}
# Prints the value of awards_wins
lord_of_the_rings_king[c("awards_wins")]
# Prints the number of awards it won, not counting the Oscars
num_awards_won
```
It does NOT!! Which is good for us. 


### Certificate

Encode `certificate`, which follows this [system](https://www.wikiwand.com/en/Motion_Picture_Association_of_America_film_rating_system) and this [one](https://www.wikiwand.com/en/TV_parental_guidelines_(US)#/TV-MA). 

```{r}
# Prints the unique values of the certificate column
unique(oscars$certificate)
# Prints the movies "Unrated" and "Not Rated"
subset(oscars, certificate == "Not Rated")[c("movie")]
subset(oscars, certificate == "Unrated")[c("movie")]
```

Let's get rid of these rows. They would only make us create more columns for `certificate`, as we can't encode them, and they are not well known movies (aside from The Great Beauty...) and didn't win any oscars. It's either this or treat `certificate` as a factor (which will be converted by R into dummies, i.e, more columns).

```{r}
# Gets the indexes of such rows
not_rated_index = as.numeric(rownames(subset(oscars, certificate == "Not Rated")[c("movie")]))
unrated_index =  as.numeric(rownames(subset(oscars, certificate == "Unrated")[c("movie")]))

# Checks if any of them won an oscar
for(i in 1:nrow(oscars[not_rated_index, ])){
  if(oscars[not_rated_index, ]$Oscars_won_some[i] == "Yes"){
    print("Yes")
  }
}
for(i in 1:nrow(oscars[unrated_index, ])){
  if(oscars[unrated_index, ]$Oscars_won_some[i] == "Yes"){
    print("Yes")
  }
}
```

Alright, let's drop'em.

```{r}
dim(oscars)
# https://github.com/tidyverse/dplyr/issues/3196
oscars = oscars %>% filter(certificate != "Not Rated" | is.na(certificate)) %>% filter(certificate != "Unrated" | is.na(certificate))
dim(oscars)
```

And now encode the column

```{r}
unique(oscars$certificate)
sum(is.na(oscars$certificate))
```

let's actually see if we can get the missing values imputed first.

```{r}
titles_missing_values = oscars[is.na(oscars$certificate), ]$movie
titles_missing_values
```

If we look up these titles in IMDB, they are not rated. Let's check once again if they won any oscars.

```{r}
for(i in titles_missing_values){
  if(subset(oscars, movie == i)$Oscars_won_some == "Yes"){
    print("Yes")}
}
```

Nop, let's drop them too.

```{r}
oscars = oscars %>% filter(is.na(certificate) == FALSE)
dim(oscars)
```

And finally let's encode it...

```{r}
unique(oscars$certificate)
oscars = oscars %>% mutate(certificate = replace(certificate, certificate == "PG-13", 3))
oscars = oscars %>% mutate(certificate = replace(certificate, certificate == "G", 1))
oscars = oscars %>% mutate(certificate = replace(certificate, certificate == "R", 4))
oscars = oscars %>% mutate(certificate = replace(certificate, certificate == "PG", 2))
oscars = oscars %>% mutate(certificate = replace(certificate, certificate == "TV-MA", 5))
oscars$certificate = as.numeric(oscars$certificate)
unique(oscars$certificate)
```


### Some more preprocessing:

```{r}
# Drops movie and movie_id, synopsis, gross and Oscars_win_count
oscars$movie <- NULL
oscars$movie_id <- NULL 
oscars$synopsis <- NULL 
oscars$gross <- NULL 
oscars$Oscars_win_count <- NULL

# Drops some others... 
oscars$year <- NULL
oscars$release_date <- NULL
oscars$Oscar_nominated_categories <- NULL 

# Drops categories for other awards (apporach 2)

# Drops the Oscars_category_won columns (will use them later as targets, but for now we cannot use them to predict)
oscars$Oscar_Best_Actor_won <- NULL
oscars$Oscar_Best_Actress_won <- NULL
oscars$Oscar_Best_AdaScreen_won <- NULL
oscars$Oscar_Best_Director_won <- NULL
oscars$Oscar_Best_OriScreen_won <- NULL
oscars$Oscar_Best_Picture_won <- NULL
oscars$Oscar_Best_Supporting_Actor_won <- NULL
oscars$Oscar_Best_Supporting_Actress_won <- NULL
```

And for when the rest of the preprocessing is done, this is for splitting. I would say let's use from 2000 to 2012 (75%) for training and from 2013 to 2016 for testing. No need to stratify as we are not doing a random split. 
```{r}
# Splits by years
oscars_train <- subset(oscars, year %in% c(2000:2012)) 
oscars_test <- subset(oscars, year %in% c(2013:2016))
# Gets the target
y_train = oscars_train$Oscars_won_some
y_test = oscars_test$Oscars_won_some
# Drops the target column
X_train <- oscars_train
X_train$Oscars_won_some <- NULL
X_test <- oscars_test
X_test$Oscars_won_some <- NULL

# Checking if our new objects make sense
head(y_train)
sapply(X_train, typeof)
```

Standardizing ([source](https://machinelearningmastery.com/pre-process-your-dataset-in-r/)).
```{r}
scaleParam <- preProcess(oscars_train, method=c("center", "scale"))
oscars_train <- predict(scaleParam, oscars_train)
oscars_test <- predict(scaleParam, oscars_test)

scaleParam <- preProcess(X_train, method=c("center", "scale"))
X_train <- predict(scaleParam, X_train)
X_test <- predict(scaleParam, X_test)

scaleParam <- preProcess(y_train, method=c("center", "scale"))
y_train <- predict(scaleParam, y_train)
y_test <- predict(scaleParam, y_test)
```

### Code for some models

Logistic Regression

```{r}
# Trains the model
oscars_train_logit <-  glm(Oscars_won_some~.,
                 family = binomial(link = "logit"), data = oscars_train)
summary(oscars_train_logit)

# Tests the model
prob_test_pred <- predict.glm(oscars_train_logit,oscars_test,type='response')
score <- sum(ifelse(prob_test_pred > 0.5,1,0)==y_test)/length(y_test)
score

# ROC Curve
prob=plogis(predict.glm(oscars_train_logit, type = c("response")))
head(prob)
h <- roc(Oscars_won_some~prob, data=oscars_train)
plot(h)
# Area Under the Curve
auc(h)

# Prints the predicted probabilities of not winning any oscar (I think this is it because "NO" comes first for both y_train and y_test) for each movie
prob_test_pred
```

Ridge Logistic Regression

```{r}
X_train_m <- model.matrix(year~., X_train)
X_test_m <- model.matrix(year~., X_test)

# Trains the model
oscars_train_ridge_logit <- glmnet(X_train_m, y_train, alpha=0, nlambda=100,
                                 lambda.min.ratio=.0001, family = binomial(link = "logit"))

# Tests the model
ridge_probs_test_pred <- predict.glmnet(oscars_train_ridge_logit, X_test_m, type="response")
score <- sum(ifelse(ridge_probs_test_pred > 0.5,1,0)==y_test)/length(y_test)
score

# ROC Curve
prob_ridge=plogis(predict.glm(oscars_train_ridge_logit, type = c("response")))
head(prob_ridge)
h <- roc(Oscars_won_some~prob_ridge, data=oscars_train)
plot(h)
# Area Under the Curve
auc(h)

# Prints the predicted probabilities of not winning any oscar for each movie
ridge_probs_test_pred
```

Lasso Logistic Regression

```{r}
# Trains the model
oscars_train_lasso_logit <- glmnet(X_train_m, y_train, family=binomial(link = "logit"), alpha=1, nlambda=100,
                                 lambda.min.ratio=.0001)

# Tests the model
lasso_probs_test_pred <- predict.glmnet(oscars_train_lasso_logit, X_test_m, type="response")
score <- sum(ifelse(lasso_probs_test_pred > 0.5,1,0)==y_test)/length(y_test)
score

# ROC Curve
prob_lasso=plogis(predict.glm(oscars_train_lasso_logit, type = c("response")))
head(prob_lasso)
h <- roc(Oscars_won_some~prob_lasso, data=oscars_train)
plot(h)
# Area Under the Curve
auc(h)

# Prints the predicted probabilities of not winning any oscar for each movie
oscars_train_lasso_logit
```

Decision Tree


```{r}

```

Cross-Validation and Hyperparameter Tuning

TODO!
```{r}

```